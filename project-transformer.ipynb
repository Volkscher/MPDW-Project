{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8824b295",
   "metadata": {},
   "source": [
    "# Transformer Encoder\n",
    "\n",
    "This notebook covers our understanding of the Tranformer Architecture as required in section 2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "model_path = 'nboost/pt-bert-base-uncased-msmarco'\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34687deb",
   "metadata": {},
   "source": [
    "## Loading the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18958da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_warning()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "# After loading the model, you can inspect its architecture. Tipycally, each model is composed by the embedding layer, the self-attention layers and the output layers. The output layer is always task specific. \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85141494",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "See here for details: https://huggingface.co/docs/transformers/tokenizer_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ef490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = [\"How many people live in Berlin?\", \"How many people live in Berlin?\"]\n",
    "sentence_b =  [\"Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\", \"New York City is famous for the Metropolitan Museum of Art.\"]\n",
    "#inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "\n",
    "pprint.pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0].tolist()))\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc006d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "pprint.pprint(input_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens_list = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "pprint.pprint(input_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\\n\".join(\"{} \\t {}\".format(x, y) for x, y in zip(input_id_list, input_tokens_list))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d961596",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80414c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f5ba9",
   "metadata": {},
   "source": [
    "## Hidden Layer Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35573ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of layers embeddings\n",
    "len(outputs['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b25a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The format is as follow:\n",
    "# outputs['hidden_states'][layer_m][0][token_n]\n",
    "layer_m = 12\n",
    "token_n = 1\n",
    "# Get all the embeddings of one layer:\n",
    "output_embeddings = outputs['hidden_states'][layer_m][0]\n",
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ffb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_throat = 2\n",
    "token_cancer = 3\n",
    "\n",
    "# Get the embedding of one particular token in one particular layer\n",
    "throat_output_embedding = outputs['hidden_states'][layer_m][0][token_throat]\n",
    "throat_output_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scatterplot(data, words):\n",
    "\n",
    "    if data.shape[1] == 2:\n",
    "        twodim = data\n",
    "    else:\n",
    "        pca = PCA()\n",
    "        pca.fit(output_embeddings.detach().numpy())\n",
    "        twodim = pca.transform(data)[:,:2]\n",
    "    \n",
    "    plt.style.use('default') # https://matplotlib.org/3.5.1/gallery/style_sheets/style_sheets_reference.html\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "    return\n",
    "\n",
    "display_scatterplot(output_embeddings.detach().numpy(), input_tokens_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
