{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfb15c5",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'video_id': ['v_QOlSCBRmfWY', 'v_ehGHCYKzyZ8', 'v_nwznKOuZM7w', 'v_ogQozSI5V8U', 'v_nHE7u40plD0', 'v_69IsHpmRyfk', 'v_D18b2IZpxk0', 'v_pizl41xmw7k', 'v_oP77DgsbhKQ', 'v_fzp5ooc727c'], 'video_path': ['https://www.youtube.com/watch?v=QOlSCBRmfWY', 'https://www.youtube.com/watch?v=ehGHCYKzyZ8', 'https://www.youtube.com/watch?v=nwznKOuZM7w', 'https://www.youtube.com/watch?v=ogQozSI5V8U', 'https://www.youtube.com/watch?v=nHE7u40plD0', 'https://www.youtube.com/watch?v=69IsHpmRyfk', 'https://www.youtube.com/watch?v=D18b2IZpxk0', 'https://www.youtube.com/watch?v=pizl41xmw7k', 'https://www.youtube.com/watch?v=oP77DgsbhKQ', 'https://www.youtube.com/watch?v=fzp5ooc727c'], 'duration': [82.7300033569336, 61.720001220703125, 31.649999618530273, 36.54999923706055, 145.55999755859375, 94.72000122070312, 95.66999816894531, 172.0800018310547, 214.60000610351562, 148.32000732421875], 'captions_starts': [[0.8299999833106995, 17.3700008392334, 56.2599983215332], [0.0, 3.0899999141693115, 15.430000305175781, 17.59000015258789, 39.810001373291016, 56.470001220703125], [0.0, 11.390000343322754], [0.0, 7.489999771118164, 19.3700008392334], [0.0, 67.68000030517578, 82.97000122070312, 98.9800033569336], [1.8899999856948853, 29.360000610351562, 55.40999984741211], [0.0, 19.610000610351562, 90.87999725341797], [0.0, 27.530000686645508, 86.04000091552734], [0.0, 41.849998474121094, 96.56999969482422, 168.4600067138672], [0.0, 15.569999694824219, 32.630001068115234, 44.5, 66.73999786376953, 74.16000366210938, 106.05000305175781, 129.77999877929688, 137.94000244140625]], 'captions_ends': [[19.860000610351562, 60.810001373291016, 79.41999816894531], [2.7799999713897705, 61.720001220703125, 55.2400016784668, 54.0, 54.619998931884766, 61.720001220703125], [15.510000228881836, 31.649999618530273], [7.489999771118164, 18.09000015258789, 36.54999923706055], [145.55999755859375, 72.77999877929688, 87.33000183105469, 103.33999633789062], [31.260000228881836, 71.51000213623047, 91.4000015258789], [17.700000762939453, 88.01000213623047, 95.66999816894531], [85.18000030517578, 43.02000045776367, 168.63999938964844], [40.77000045776367, 119.0999984741211, 170.61000061035156, 214.60000610351562], [14.829999923706055, 32.630001068115234, 44.5, 65.26000213623047, 72.68000030517578, 107.52999877929688, 130.52000427246094, 137.94000244140625, 148.32000732421875]], 'en_captions': [['A young woman is seen standing in a room and leads into her dancing.', ' The girl dances around the room while the camera captures her movements.', ' She continues dancing around the room and ends by laying on the floor.'], ['The video starts with a title logo sequence.', ' A man and woman are in a living room demonstrating exercises.', ' The woman lays on the ground.', \" The man starts pointing to different areas of the woman's body as she does an exercise.\", ' The woman begins to do small sit ups.', ' The woman ends with a final title logo sequence.'], ['Two people are seen moving around a kitchen quickly performing various tasks and sitting down.', ' They then wax down a ski in the kitchen while continuing to move around.'], ['We see a hallway with a wooden floor.', ' A dog in socks walks slowly out onto the floor as a lady films him.', ' The dog turns around and goes back to the other room.'], ['A woman and a man are sitting on the sidewalk playing music.', ' People stand next to them and watch them play.', ' A little boy holding a yellow ball walks by.', ' A man poses for a picture in front of them.'], ['A young girl is seen sitting in a chair with a person standing next to her.', ' The person next to her then piercing one ear followed by the other.', ' The person rubs lotion on the piercings afterwards.'], ['A woman is shown riding a camel past pyramids in Egypt.', ' The camel walks as the woman leans forward.', ' And hand covers the lens as the harness is shown.'], ['A child mops the floor of a hallway in a house.', ' The child sets the mop down and plays with her family member.', ' The child walks into the bedroom area and continues to mop the floor.'], ['A man is seen kneeling down on the floor speaking to the camera.', ' The man mixes up various ingredients and begins laying plaster on the floor.', ' He measures the floor and tiles and cuts out a piece of tile to lay on the floor.', ' He continues laying tiles on the floor while looking back to speak to the camera.'], ['Two lines of young men are walking side by side down a road.', 'Then one man stands in a field holding a wooden object and begins twisting it.', 'He then bends down and grabs a ball.', \"After,the ball is placed on the ground and he picks it up and hits it as if he's playing baseball.\", 'The ball is thrown back and he its it again.', 'Shortly after, a field of men are shown and they begin playing a game against one another.', 'There was a penalty and one players attempts to hit the ball into the goal from the side.', 'After,everyone is pictured lying down on the ground as if they are dead but one person begins to sit up but gets hit in the head by the ball and lays back down.', 'Lastly,the screen flashes to a black screen and the words The End are shown.']]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['A young woman is seen standing in a room and leads into her dancing.',\n",
       "  ' The girl dances around the room while the camera captures her movements.',\n",
       "  ' She continues dancing around the room and ends by laying on the floor.'],\n",
       " ['The video starts with a title logo sequence.',\n",
       "  ' A man and woman are in a living room demonstrating exercises.',\n",
       "  ' The woman lays on the ground.',\n",
       "  \" The man starts pointing to different areas of the woman's body as she does an exercise.\",\n",
       "  ' The woman begins to do small sit ups.',\n",
       "  ' The woman ends with a final title logo sequence.'],\n",
       " ['Two people are seen moving around a kitchen quickly performing various tasks and sitting down.',\n",
       "  ' They then wax down a ski in the kitchen while continuing to move around.'],\n",
       " ['We see a hallway with a wooden floor.',\n",
       "  ' A dog in socks walks slowly out onto the floor as a lady films him.',\n",
       "  ' The dog turns around and goes back to the other room.'],\n",
       " ['A woman and a man are sitting on the sidewalk playing music.',\n",
       "  ' People stand next to them and watch them play.',\n",
       "  ' A little boy holding a yellow ball walks by.',\n",
       "  ' A man poses for a picture in front of them.'],\n",
       " ['A young girl is seen sitting in a chair with a person standing next to her.',\n",
       "  ' The person next to her then piercing one ear followed by the other.',\n",
       "  ' The person rubs lotion on the piercings afterwards.'],\n",
       " ['A woman is shown riding a camel past pyramids in Egypt.',\n",
       "  ' The camel walks as the woman leans forward.',\n",
       "  ' And hand covers the lens as the harness is shown.'],\n",
       " ['A child mops the floor of a hallway in a house.',\n",
       "  ' The child sets the mop down and plays with her family member.',\n",
       "  ' The child walks into the bedroom area and continues to mop the floor.'],\n",
       " ['A man is seen kneeling down on the floor speaking to the camera.',\n",
       "  ' The man mixes up various ingredients and begins laying plaster on the floor.',\n",
       "  ' He measures the floor and tiles and cuts out a piece of tile to lay on the floor.',\n",
       "  ' He continues laying tiles on the floor while looking back to speak to the camera.'],\n",
       " ['Two lines of young men are walking side by side down a road.',\n",
       "  'Then one man stands in a field holding a wooden object and begins twisting it.',\n",
       "  'He then bends down and grabs a ball.',\n",
       "  \"After,the ball is placed on the ground and he picks it up and hits it as if he's playing baseball.\",\n",
       "  'The ball is thrown back and he its it again.',\n",
       "  'Shortly after, a field of men are shown and they begin playing a game against one another.',\n",
       "  'There was a penalty and one players attempts to hit the ball into the goal from the side.',\n",
       "  'After,everyone is pictured lying down on the ground as if they are dead but one person begins to sit up but gets hit in the head by the ball and lays back down.',\n",
       "  'Lastly,the screen flashes to a black screen and the words The End are shown.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset and indexing its data\n",
    "\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset, trust_remote_code=True is needed to load the dataset from the remote repository.\n",
    "dataset = load_dataset('dataset-download.py', trust_remote_code=True) \n",
    "\n",
    "doc_list = [dataset['train'][:10]] # Load the first 10 examples of the dataset\n",
    "\n",
    "print(doc_list)  # Print the first example of the dataset\n",
    "\n",
    "doc_list[0]['en_captions']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824b295",
   "metadata": {},
   "source": [
    "# Transformer Encoder\n",
    "\n",
    "This notebook covers our understanding of the Tranformer Architecture as required in section 2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426fdef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (c:\\Users\\rafae\\Desktop\\MPDW-Project\\.venv\\Lib\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbertviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m head_view\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Get the interactive Tools for Matplotlib\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#%matplotlib notebook\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#%matplotlib inline\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rafae\\Desktop\\MPDW-Project\\.venv\\Lib\\site-packages\\bertviz\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhead_view\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m head_view\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_view\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_view\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rafae\\Desktop\\MPDW-Project\\.venv\\Lib\\site-packages\\bertviz\\head_view.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML, Javascript\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_special_chars, format_attention, num_layers\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhead_view\u001b[39m(\n\u001b[32m     11\u001b[39m         attention=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     12\u001b[39m         tokens=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m         html_action=\u001b[33m'\u001b[39m\u001b[33mview\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     24\u001b[39m ):\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (c:\\Users\\rafae\\Desktop\\MPDW-Project\\.venv\\Lib\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from bertviz import model_view, head_view\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "model_path = 'nboost/pt-bert-base-uncased-msmarco'\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34687deb",
   "metadata": {},
   "source": [
    "## Loading the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18958da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_warning()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "# After loading the model, you can inspect its architecture. Tipycally, each model is composed by the embedding layer, the self-attention layers and the output layers. The output layer is always task specific. \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85141494",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "See here for details: https://huggingface.co/docs/transformers/tokenizer_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ef490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_a = [\"How many people live in Berlin?\", \"How many people live in Berlin?\"]\n",
    "#sentence_b =  [\"Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\", \"New York City is famous for the Metropolitan Museum of Art.\"]\n",
    "captions = doc_list[0]['en_captions']\n",
    "#inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs = tokenizer(captions, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "\n",
    "print.pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0].tolist()))\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc006d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "pprint.pprint(input_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens_list = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "pprint.pprint(input_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\\n\".join(\"{} \\t {}\".format(x, y) for x, y in zip(input_id_list, input_tokens_list))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d961596",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80414c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f5ba9",
   "metadata": {},
   "source": [
    "## Hidden Layer Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35573ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of layers embeddings\n",
    "len(outputs['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b25a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The format is as follow:\n",
    "# outputs['hidden_states'][layer_m][0][token_n]\n",
    "layer_m = 12\n",
    "token_n = 1\n",
    "# Get all the embeddings of one layer:\n",
    "output_embeddings = outputs['hidden_states'][layer_m][0]\n",
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ffb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_throat = 2\n",
    "token_cancer = 3\n",
    "\n",
    "# Get the embedding of one particular token in one particular layer\n",
    "throat_output_embedding = outputs['hidden_states'][layer_m][0][token_throat]\n",
    "throat_output_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scatterplot(data, words):\n",
    "\n",
    "    if data.shape[1] == 2:\n",
    "        twodim = data\n",
    "    else:\n",
    "        pca = PCA()\n",
    "        pca.fit(output_embeddings.detach().numpy())\n",
    "        twodim = pca.transform(data)[:,:2]\n",
    "    \n",
    "    plt.style.use('default') # https://matplotlib.org/3.5.1/gallery/style_sheets/style_sheets_reference.html\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "    return\n",
    "\n",
    "display_scatterplot(output_embeddings.detach().numpy(), input_tokens_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
