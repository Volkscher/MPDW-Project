{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Week 1: ActivityNet Video Data Preparation and Indexing\n",
    "\n",
    "In this example we will use the ActivityNet dataset https://github.com/activitynet/ActivityNet. \n",
    "\n",
    " - Select the 10 videos with more moments.\n",
    " - Download these videos onto your computer.\n",
    " - Extract the frames for every video.\n",
    " - Read the textual descriptions of each video.\n",
    " - Index the video data in OpenSearch.\n",
    "\n",
    " In this week, you will index the video data and make it searchable with OpenSearch. You should refer to the OpenSearch tutorial laboratory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select videos\n",
    "Download the `activity_net.v1-3.min.json` file containing the list of videos. The file is in the github repository of ActivityNet.\n",
    "Parse this file and select the 10 videos with more moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['duration', 'subset', 'resolution', 'url', 'annotations'])\n",
      "o1WPnnvs00I - 23 moments\n",
      "oGwn4NUeoy8 - 23 moments\n",
      "VEDRmPt_-Ms - 20 moments\n",
      "qF3EbR8y8go - 19 moments\n",
      "DLJqhYP-C0k - 18 moments\n",
      "t6f_O8a4sSg - 18 moments\n",
      "6gyD-Mte2ZM - 18 moments\n",
      "jBvGvVw3R-Q - 18 moments\n",
      "PJ72Yl0B1rY - 17 moments\n",
      "QHn9KyE-zZo - 17 moments\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#[('o1WPnnvs00I', {'duration': 229.86, 'subset': 'training', 'resolution': '640x480',\n",
    "data:list\n",
    "\n",
    "with open('activity_net.v1-3.min.json', 'r') as json_data:\n",
    "    data = json.load(json_data)\n",
    "    \n",
    "    # 'database' is a <key, valu> pair -> <video_id, video_info>\n",
    "    videos = data['database']\n",
    "    \n",
    "    # Sort the list by number of annotations (video moments)\n",
    "    sorted_list = sorted(videos.items(), key= lambda x: len(x[1]['annotations']), reverse = True)\n",
    "\n",
    "    # Select the top 10 videos \n",
    "    top_10_videos = sorted_list[:10]\n",
    "\n",
    "    # Convert the list of tuples to a dictionary before dumping\n",
    "    top_10_dict = {video_id: video_info for video_id, video_info in top_10_videos}\n",
    "\n",
    "    # Check the video id and number of moments of the items in the list\n",
    "    for video_id, video_info in top_10_videos:\n",
    "        print(f\"{video_id} - {len(video_info['annotations'])} moments\")\n",
    "\n",
    "    #print(top_10_dict.keys) # Each key is a video id\n",
    "\n",
    "with open('top10.json', 'w') as file: # Gotta use the full relative path if running on a python notebook\n",
    "    json.dump(top_10_dict, file, indent=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video frame extraction\n",
    "\n",
    "PyAV is a wrapper library providing you access to `ffmpeg`, a command-line video processing tool. In the example below, you will be able to extract frames from the a video shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<av.VideoFrame, pts=0 yuv420p 1280x720 at 0x7fe5544f1ea0>\n",
      "<av.VideoFrame, pts=75 yuv420p 1280x720 at 0x7fe52a097100>\n",
      "<av.VideoFrame, pts=150 yuv420p 1280x720 at 0x7fe52d401660>\n"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import av.datasets\n",
    "\n",
    "content = av.datasets.curated(\"pexels/time-lapse-video-of-night-sky-857195.mp4\")\n",
    "with av.open(content) as container:\n",
    "    # Signal that we only want to look at keyframes.\n",
    "    stream = container.streams.video[0]\n",
    "    stream.codec_context.skip_frame = \"NONKEY\"\n",
    "\n",
    "    for i, frame in enumerate(container.decode(stream)):\n",
    "        print(frame)\n",
    "        frame.to_image().save(f\"night-sky.{i:04d}.jpg\", quality=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video metadata\n",
    "\n",
    "Process the video metadata provided in the `json` file and index the video data in OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'user13' created successfully!\n"
     ]
    }
   ],
   "source": [
    "## New Index Mappings for k-nn vectors and embeddings\n",
    "## (embeddings are the means from the words extracted from the captions)\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "import requests\n",
    "from opensearchpy import helpers\n",
    "\n",
    "host = 'api.novasearch.org'\n",
    "port = 443\n",
    "\n",
    "user = 'user13' \n",
    "password = 'rumoao+20' \n",
    "index_name = user # We can only have an index with the same name has our user name.\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = (user, password),\n",
    "    use_ssl = True,\n",
    "    url_prefix = 'opensearch_v2',\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False\n",
    ")\n",
    "\n",
    "# The fields and how they are searched and how important they are, are defined in the mappings\n",
    "index_body = {\n",
    "   \"settings\":{\n",
    "      \"index\":{\n",
    "         \"number_of_replicas\":0,\n",
    "         \"number_of_shards\":4,\n",
    "         \"refresh_interval\":\"-1\",\n",
    "         \"knn\":\"true\"\n",
    "      }\n",
    "   },\n",
    "   \"mappings\":{\n",
    "       \"dynamic\":      \"strict\", # Prevents accidental addition of new fields to the index. This way indexed documents must match the index mapping.\n",
    "       \"properties\":{\n",
    "         \"video_id\":{\n",
    "            \"type\":\"keyword\"\n",
    "         },\n",
    "         \"title\":{\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\":\"english\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         },\n",
    "         \"video_path\":{\n",
    "            \"type\":\"text\"\n",
    "         },\n",
    "         \"duration\":{\n",
    "            \"type\":\"float\"\n",
    "         },\n",
    "         \"description\":{  # The description field is a text field of the join from the en_captions field that is an array of strings.\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\":\"english\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         },\n",
    "        \"description_embedding\":{\n",
    "            \"type\":\"knn_vector\",\n",
    "            \"dimension\": 768,\n",
    "            \"method\":{\n",
    "               \"name\":\"hnsw\",\n",
    "               \"space_type\":\"innerproduct\", # cosinesimil > innerproduct  because the captions are normalized and this provides better semantic similarity\n",
    "               \"engine\":\"faiss\",\n",
    "               \"parameters\":{\n",
    "                  \"ef_construction\":256,\n",
    "                  \"m\":48\n",
    "               }\n",
    "            }\n",
    "        },\n",
    "        \"annotations\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"segment\": {\"type\": \"float\"},\n",
    "                    \"label\": {\"type\": \"text\"},\n",
    "                    \"is_answer\": {\"type\": \"boolean\"},\n",
    "                    \"confidence\": {\"type\": \"float\"}\n",
    "                }\n",
    "        },\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# Create the index with the specified mappings and settings\n",
    "response = client.indices.create(index=index_name, body=index_body)\n",
    "\n",
    "# Check if the index creation was successful\n",
    "if response['acknowledged']:\n",
    "    print(f\"Index '{index_name}' created successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to create index: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1WPnnvs00I - {'segment': [4.303033313169262, 13.626272158369328], 'label': 'Playing flauta'}\n",
      "229.86\n",
      "oGwn4NUeoy8 - {'segment': [37.01843986684637, 42.0338413971933], 'label': 'Playing congas'}\n",
      "153.09\n",
      "VEDRmPt_-Ms - {'segment': [15.568780241809671, 21.723879407176288], 'label': 'Tumbling'}\n",
      "232.07999999999998\n",
      "qF3EbR8y8go - {'segment': [2.865726384157407, 9.55242128052469], 'label': 'Painting'}\n",
      "204.1\n",
      "DLJqhYP-C0k - {'segment': [11.083851549980366, 16.62577732497055], 'label': 'Playing ten pins'}\n",
      "186.968\n",
      "t6f_O8a4sSg - {'segment': [14.999980897195073, 30.681779107899008], 'label': 'Skateboarding'}\n",
      "218.52\n",
      "6gyD-Mte2ZM - {'segment': [21.43810386973302, 32.59766478822418], 'label': 'Playing ten pins'}\n",
      "188.245\n",
      "jBvGvVw3R-Q - {'segment': [19.776733229329174, 23.868471138845557], 'label': 'Snatch'}\n",
      "218.62\n",
      "PJ72Yl0B1rY - {'segment': [10.941581903276132, 24.457653666146648], 'label': 'Beach soccer'}\n",
      "206.332\n",
      "QHn9KyE-zZo - {'segment': [0.01, 7.961349719294894], 'label': 'Slacklining'}\n",
      "196.279\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Git Repositories/MPDW-Project/top10.json', 'r') as data:\n",
    "    data = json.load(data).items()\n",
    "\n",
    "    # Check the video id and number of moments of the items in the list\n",
    "    for video_id, video_info in data:\n",
    "        print(f\"{video_id} - {video_info['annotations'][0]}\")\n",
    "        print(video_info['duration'])\n",
    "\n",
    "        # Creating the document to be indexed from the video in the dataset\n",
    "        doc = {\n",
    "            'video_id': video_id, # Document ID\n",
    "            'title': video_info['annotations'][0]['label'], # Title\n",
    "            'video_path': video_info['url'], # Video path\n",
    "            'description': \"\",\n",
    "            'duration': 10,\n",
    "            \"annotations\": video_info['annotations']\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc found\n",
      "Updated description for video_id: DLJqhYP-C0k\n",
      "doc found\n",
      "Updated description for video_id: qF3EbR8y8go\n",
      "doc found\n",
      "Updated description for video_id: oGwn4NUeoy8\n",
      "doc found\n",
      "Updated description for video_id: VEDRmPt_-Ms\n",
      "doc found\n",
      "Updated description for video_id: o1WPnnvs00I\n",
      "doc found\n",
      "Updated description for video_id: jBvGvVw3R-Q\n",
      "doc found\n",
      "Updated description for video_id: t6f_O8a4sSg\n",
      "doc found\n",
      "Updated description for video_id: 6gyD-Mte2ZM\n",
      "doc found\n",
      "Updated description for video_id: QHn9KyE-zZo\n",
      "doc found\n",
      "Updated description for video_id: PJ72Yl0B1rY\n",
      "doc found\n",
      "Updated description for video_id: t6f_O8a4sSg\n",
      "doc found\n",
      "Updated description for video_id: 6gyD-Mte2ZM\n",
      "doc found\n",
      "Updated description for video_id: QHn9KyE-zZo\n",
      "doc found\n",
      "Updated description for video_id: PJ72Yl0B1rY\n",
      "{'_index': 'user13', '_id': '0', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '1', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '2', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '3', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 2, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '4', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '5', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '6', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 3, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '7', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '8', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '9', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 4, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset and indexing it\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset, trust_remote_code=True is needed to load the dataset from the remote repository.\n",
    "dataset = load_dataset('dataset-download.py', trust_remote_code=True) \n",
    "\n",
    "doc_list = []\n",
    "\n",
    "index_number_id = 0 # Index number to use as document ID (0, 1, 2, ...)\n",
    "\n",
    "with open('C:/Git Repositories/MPDW-Project/top10.json', 'r') as data:\n",
    "    data = json.load(data).items()\n",
    "\n",
    "    # Check the video id and number of moments of the items in the list\n",
    "    for video_id, video_info in data:\n",
    "        # Creating the document to be indexed from the video in the dataset\n",
    "        doc = {\n",
    "            'video_id': video_id, # Document ID\n",
    "            'title': video_info['annotations'][0]['label'], # Title\n",
    "            'video_path': video_info['url'], # Video path\n",
    "            'description': \"\",\n",
    "            'duration': video_info['duration'],\n",
    "            \"annotations\": video_info['annotations']\n",
    "        }\n",
    "\n",
    "        doc_list.append(doc)\n",
    "        #print(len(doc_list))\n",
    "\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    for video in dataset[split]:\n",
    "        # Iterate through the documents in doc_list\n",
    "        for doc in doc_list:\n",
    "            #print(video['video_id'].replace(\"v_\", \"\"))\n",
    "            video['video_id'] = video['video_id'].replace(\"v_\", \"\") # clean the video_key from the captions dataset, it comes with the format v_<key> instead of just <key>\n",
    "\n",
    "            if doc['video_id'] == video['video_id']:  # Check if the video_id matches\n",
    "                print(\"doc found\")\n",
    "                \n",
    "                description = \"\"  # Initialize the description string\n",
    "\n",
    "                # Combine all the captions into the description\n",
    "                for caption in video['en_captions']:\n",
    "                    description += f\" {caption}\"\n",
    "\n",
    "                # Update the document's description\n",
    "                doc['description'] = description\n",
    "\n",
    "                # Debugging print to confirm update\n",
    "                print(f\"Updated description for video_id: {doc['video_id']}\")\n",
    "\n",
    "# Make sure all the fields are filled\n",
    "#print(doc_list)\n",
    "#print(len(doc_list)) \n",
    "\n",
    "for doc in doc_list:\n",
    "    response = client.index(index = index_name, id= index_number_id, body = doc)\n",
    "    \n",
    "    print(response)\n",
    "    \n",
    "    index_number_id+= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'user13', '_id': '0', '_version': 1, '_seq_no': 0, '_primary_term': 1, 'found': True, '_source': {'video_id': 'o1WPnnvs00I', 'title': 'Playing flauta', 'video_path': 'https://www.youtube.com/watch?v=o1WPnnvs00I', 'description': ' A man is playing a flute in front of a microphone.  A few other men are shown playing guitars as they sit.  The group plays for the audience, occasionally zooming in on individuals.  One man is playing drums while the others are on flute and guitar.  The lights move fluidly as they crescendo, and they screen goes black.', 'duration': 229.86, 'annotations': [{'segment': [4.303033313169262, 13.626272158369328], 'label': 'Playing flauta'}, {'segment': [17.92930547153859, 24.025269212168485], 'label': 'Playing flauta'}, {'segment': [28.68688861154446, 35.50002465678627], 'label': 'Playing flauta'}, {'segment': [39.085885733229325, 40.52023016380655], 'label': 'Playing flauta'}, {'segment': [45.89902177847114, 48.767710639625584], 'label': 'Playing flauta'}, {'segment': [59.16670776131045, 63.469741053042114], 'label': 'Playing flauta'}, {'segment': [68.1313604524181, 95.02531852574101], 'label': 'Playing flauta'}, {'segment': [98.96976570982838, 99.686937925117], 'label': 'Playing flauta'}, {'segment': [100.7626962480499, 108.65159061622464], 'label': 'Playing flauta'}, {'segment': [111.16169336973478, 111.52027947737909], 'label': 'Playing flauta'}, {'segment': [114.38896833853353, 120.84351827613104], 'label': 'Playing flauta'}, {'segment': [125.50513767550702, 128.73241264430575], 'label': 'Playing flauta'}, {'segment': [131.95968761310453, 140.56575419656784], 'label': 'Playing flauta'}, {'segment': [143.075856950078, 157.06071514820593], 'label': 'Playing flauta'}, {'segment': [158.49505957878316, 162.0809206552262], 'label': 'Playing flauta'}, {'segment': [164.59102340873633, 166.3839539469579], 'label': 'Playing flauta'}, {'segment': [168.894056700468, 171.04557334633384], 'label': 'Playing flauta'}, {'segment': [173.1970899921997, 190.40922315912636], 'label': 'Playing flauta'}, {'segment': [193.9950842355694, 194.712256450858], 'label': 'Playing flauta'}, {'segment': [204.7526674648986, 212.6415618330733], 'label': 'Playing flauta'}, {'segment': [214.43449237129485, 217.66176734009358], 'label': 'Playing flauta'}, {'segment': [219.81328398595943, 221.24762841653666], 'label': 'Playing flauta'}, {'segment': [222.68197284711388, 224.8334894929797], 'label': 'Playing flauta'}]}}\n"
     ]
    }
   ],
   "source": [
    "response = client.get(id = 0, index=index_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video captions\n",
    "\n",
    "The ActivityNetCaptions dataset https://cs.stanford.edu/people/ranjaykrishna/densevid/ dataset provides a textual description of each videos. Index the video captions on a text field of your OpenSearch index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
