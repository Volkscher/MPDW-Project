{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "In this notebook, we retrieve the videos and their captions from 2 different datasets, join their information and index them. Additionally, we implement 3 search methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting 10 videos \n",
    "This section creates a json file of the top 10 videos from the activitynet videos dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1WPnnvs00I - 23 moments\n",
      "oGwn4NUeoy8 - 23 moments\n",
      "VEDRmPt_-Ms - 20 moments\n",
      "qF3EbR8y8go - 19 moments\n",
      "DLJqhYP-C0k - 18 moments\n",
      "t6f_O8a4sSg - 18 moments\n",
      "6gyD-Mte2ZM - 18 moments\n",
      "jBvGvVw3R-Q - 18 moments\n",
      "PJ72Yl0B1rY - 17 moments\n",
      "QHn9KyE-zZo - 17 moments\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#[('o1WPnnvs00I', {'duration': 229.86, 'subset': 'training', 'resolution': '640x480',\n",
    "data:list\n",
    "\n",
    "with open('activity_net.v1-3.min.json', 'r') as json_data:\n",
    "    data = json.load(json_data)\n",
    "    \n",
    "    # 'database' is a <key, valu> pair -> <video_id, video_info>\n",
    "    videos = data['database']\n",
    "    \n",
    "    # Sort the list by number of annotations (video moments)\n",
    "    sorted_list = sorted(videos.items(), key= lambda x: len(x[1]['annotations']), reverse = True)\n",
    "\n",
    "    # Select the top 10 videos \n",
    "    top_10_videos = sorted_list[:10]\n",
    "\n",
    "    # Convert the list of tuples to a dictionary before dumping\n",
    "    top_10_dict = {video_id: video_info for video_id, video_info in top_10_videos}\n",
    "\n",
    "    # Check the video id and number of moments of the items in the list\n",
    "    for video_id, video_info in top_10_videos:\n",
    "        print(f\"{video_id} - {len(video_info['annotations'])} moments\")\n",
    "\n",
    "    #print(top_10_dict.keys) # Each key is a video id\n",
    "\n",
    "with open('top10.json', 'w') as file: # Gotta use the full relative path if running on a python notebook\n",
    "    json.dump(top_10_dict, file, indent=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Metadata Indexing\n",
    "\n",
    "In this section we process the selected videos from our json file.\n",
    "We first start by creating the OpenSearch index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'user13' created successfully!\n"
     ]
    }
   ],
   "source": [
    "## New Index Mappings for k-nn vectors and embeddings\n",
    "## (embeddings are the means from the words extracted from the captions)\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "import requests\n",
    "from opensearchpy import helpers\n",
    "\n",
    "host = 'api.novasearch.org'\n",
    "port = 443\n",
    "\n",
    "user = 'user13' \n",
    "password = 'rumoao+20' \n",
    "index_name = user # We can only have an index with the same name has our user name.\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = (user, password),\n",
    "    use_ssl = True,\n",
    "    url_prefix = 'opensearch_v2',\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False\n",
    ")\n",
    "\n",
    "# The fields and how they are searched and how important they are, are defined in the mappings\n",
    "index_body = {\n",
    "   \"settings\":{\n",
    "      \"index\":{\n",
    "         \"number_of_replicas\":0,\n",
    "         \"number_of_shards\":4,\n",
    "         \"refresh_interval\":\"-1\",\n",
    "         \"knn\":\"true\"\n",
    "      }\n",
    "   },\n",
    "   \"mappings\":{\n",
    "       \"dynamic\":      \"strict\", # Prevents accidental addition of new fields to the index. This way indexed documents must match the index mapping.\n",
    "       \"properties\":{\n",
    "         \"video_id\":{\n",
    "            \"type\":\"keyword\"\n",
    "         },\n",
    "         \"title\":{\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\":\"english\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         },\n",
    "         \"video_path\":{\n",
    "            \"type\":\"text\"\n",
    "         },\n",
    "         \"duration\":{\n",
    "            \"type\":\"float\"\n",
    "         },\n",
    "         \"description\":{  # The description field is a text field of the join from the en_captions field that is an array of strings.\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\":\"english\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         },\n",
    "        \"description_embedding\":{\n",
    "            \"type\":\"knn_vector\",\n",
    "            \"dimension\": 384,\n",
    "        },\n",
    "        \"annotations\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"segment\": {\"type\": \"float\"},\n",
    "                    \"label\": {\"type\": \"text\"},\n",
    "                    \"is_answer\": {\"type\": \"boolean\"},\n",
    "                    \"confidence\": {\"type\": \"float\"}\n",
    "                }\n",
    "        },\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# Create the index with the specified mappings and settings\n",
    "response = client.indices.create(index=index_name, body=index_body)\n",
    "\n",
    "# Check if the index creation was successful\n",
    "if response['acknowledged']:\n",
    "    print(f\"Index '{index_name}' created successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to create index: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "{'_index': 'user13', '_id': '0', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '1', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '2', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '3', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 2, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '4', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '5', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '6', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 3, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '7', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '8', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1}\n",
      "{'_index': 'user13', '_id': '9', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 4, '_primary_term': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_shards': {'total': 4, 'successful': 4, 'failed': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset and indexing its data\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset, trust_remote_code=True is needed to load the dataset from the remote repository.\n",
    "dataset = load_dataset('dataset-download.py', trust_remote_code=True) \n",
    "\n",
    "doc_list = []\n",
    "\n",
    "index_number_id = 0 # Index number to use as document ID (0, 1, 2, ...)\n",
    "\n",
    "with open('C:/Git Repositories/MPDW-Project/top10.json', 'r') as data:\n",
    "    data = json.load(data).items()\n",
    "\n",
    "    # Check the video id and number of moments of the items in the list\n",
    "    for video_id, video_info in data:\n",
    "        # Creating the document to be indexed from the video in the dataset\n",
    "        doc = {\n",
    "            'video_id': video_id, # Document ID\n",
    "            'title': video_info['annotations'][0]['label'], # Title\n",
    "            'video_path': video_info['url'], # Video path\n",
    "            'description': \"\",\n",
    "            'duration': video_info['duration'],\n",
    "            \"annotations\": video_info['annotations']\n",
    "        }\n",
    "\n",
    "        doc_list.append(doc)\n",
    "\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    for video in dataset[split]:\n",
    "        # Iterate through the documents in doc_list\n",
    "        for doc in doc_list:\n",
    "            #print(video['video_id'].replace(\"v_\", \"\"))\n",
    "            video['video_id'] = video['video_id'].replace(\"v_\", \"\") # clean the video_key from the captions dataset, it comes with the format v_<key> instead of just <key>\n",
    "\n",
    "            if doc['video_id'] == video['video_id']:  # Check if the video_id matches\n",
    "                description = \"\"  # Initialize the description string\n",
    "\n",
    "                # Combine all the captions into the description\n",
    "                for caption in video['en_captions']:\n",
    "                    description += f\" {caption}\"\n",
    "\n",
    "                # Update the document's description\n",
    "                doc['description'] = description\n",
    "\n",
    "                # Embed the document's description\n",
    "                #embedded_description = encode(video['en_captions']).numpy()\n",
    "                #doc['description_embedding'] = embedded_description\n",
    "\n",
    "# Loading \n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(model.get_sentence_embedding_dimension())\n",
    "\n",
    "# Sending the docs to the opensearch index\n",
    "for doc in doc_list:\n",
    "    doc['description_embedding'] = model.encode(doc['description']).tolist()\n",
    "\n",
    "    response = client.index(index = index_name, id= index_number_id, body = doc)\n",
    "    \n",
    "    print(response)\n",
    "    \n",
    "    index_number_id+= 1\n",
    "\n",
    "# Refresh the index so the docs are searchable (we weren't getting hits because of this...)\n",
    "client.indices.refresh(index = 'user13')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Query Search Types:\n",
    "- text based search\n",
    "- embeddings based search\n",
    "- boolean filters alone\n",
    "- search with boolean filters (Not Return Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qF3EbR8y8go 1.4283175 Painting  woman is painting in a white paper green leaves in a chinese tree.  a red paint is shown and woman put a stamp on the corner of the paper.  woman is painting a blue ad purple chinese flower.  a red and black flowers are painted on a white paper with very detail for the same woman in a dark room.  woman used some black painting for make details, put the red stamp on the corner and finished the painting with yellow and reddetails on the flowers.\n",
      "oGwn4NUeoy8 0.9529365 Playing congas  A small group of people are seen on a stage getting their instruments ready.  A woman begins playing the drums while another plays piano and the others watch.  The two continue to play their instruments and others on the side watch.\n",
      "PJ72Yl0B1rY 0.664531 Beach soccer  A group of athletes play beach soccer in several different games and locations surrounded by audiences in bleachers and dancing cheerleaders.  A group of soccer players play beach soccer while an audience claps for them and cheerleaders perform routines in between video clips.   The men are shown winning trophies and making soccer goals until a final sponsor, marketing graphic appears.\n"
     ]
    }
   ],
   "source": [
    "# Simple Text Based Search\n",
    "\n",
    "prompt = \"a woman appears\"\n",
    "\n",
    "query_bm25 = {\n",
    "  'size': 5, # Number of max results to return\n",
    "  '_source': ['video_id', 'title', 'description'], # Index Fields to return\n",
    "  'query': {\n",
    "    'multi_match': {\n",
    "      'query': prompt,\n",
    "      'fields': ['description', 'title'] # Index Fields to search\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = 'user13'\n",
    ")\n",
    "\n",
    "#print(response['hits']['hits']) -> how to view the list of hits\n",
    "\n",
    "# Print each hit\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_source']['video_id'], hit['_score'], hit['_source']['title'], hit['_source']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.56289667, Video ID: qF3EbR8y8go\n",
      "Score: 0.36608934, Video ID: oGwn4NUeoy8\n",
      "Score: 0.35299662, Video ID: VEDRmPt_-Ms\n",
      "Score: 0.3317406, Video ID: 6gyD-Mte2ZM\n",
      "Score: 0.32351676, Video ID: o1WPnnvs00I\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Base Search\n",
    "\n",
    "query_text = \"A woman painting\" # Should return at least 1 video with the id qF3EbR8y8go, because this one for sure has a woman painting\n",
    "query_vector = model.encode(query_text).tolist()\n",
    "\n",
    "# Perform the k-NN search on the description_embedding field\n",
    "search_body = {\n",
    "    \"size\": 5,  # Number of max results to return\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"description_embedding\": {\n",
    "                \"vector\": query_vector,\n",
    "                \"k\": 5  # Number of nearest neighbors to return\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.search(index=index_name, body=search_body)\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Score: {hit['_score']}, Video ID: {hit['_source']['video_id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.4283175, Video ID: qF3EbR8y8go\n",
      "Score: 0.9529365, Video ID: oGwn4NUeoy8\n",
      "Score: 0.664531, Video ID: PJ72Yl0B1rY\n"
     ]
    }
   ],
   "source": [
    "# Boolean Based Search\n",
    "filter = 'Painting'\n",
    "\n",
    "search_body = {\n",
    "    \"size\": 5,  # Number of max results to return\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"term\": {  \n",
    "                        # The index fields to base our boolean search on\n",
    "                        \"annotations.label\": filter  # videos with the label \"Painting\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform the search query\n",
    "response = client.search(index=index_name, body=search_body)\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Score: {hit['_score']}, Video ID: {hit['_source']['video_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text and Boolean Search\n",
    "# Unfortunately results are not being returned, so this is not working yet.\n",
    "prompt = \"a woman painting\"  \n",
    "filter = \"Painting\"  \n",
    "\n",
    "search_body = {\n",
    "    \"size\": 5,  # Number of results to return\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\":{\n",
    "                \"match\": {\n",
    "                    \"annotations.label\": filter  # videos with the label \"Painting\"\n",
    "                }\n",
    "            },\n",
    "            \"should\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": prompt,\n",
    "                    \"fields\": [\"description\", \"title\"]  # Index Fields to search\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform the search query\n",
    "response = client.search(index=index_name, body=search_body)\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Score: {hit['_score']}, Video ID: {hit['_source']['video_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Deletion\n",
    "\n",
    "Run the cell bellow whenever we need to delete the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This line is here to prevent you from inadvertently deleting data.\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index.\n",
    "    response = client.indices.delete(\n",
    "        index = index_name\n",
    "    )\n",
    "    print('\\nDeleting index:')\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
